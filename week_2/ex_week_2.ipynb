{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - Convolution (or filtering)\n",
    "\n",
    "- Rewrite to use same \"wording\" and \"Coding\" as week 1\n",
    "- Ensure mathematical terms correspond to the book\n",
    "- Add stuff about PCA perhaps? Either that or introduce convolution for neural networks OR convolution for filtering.\n",
    "  - Perhaps intro to entropy and cross entropy?\n",
    "- Add exercise about using kernels with very big or very small values, since typically convolutions truncate between 0 to 255\n",
    "- Add cross entropy to the bottom of the exercises\n",
    "- Implement convolution manually as extra\n",
    "\n",
    "We are going to use images in the form of multidimensional arrays of data (a 2D matrix for a grayscale image and  3 2D matrices in case of a RGB image) and the kernel will be a 2D matrix (usually square with an odd number of rows/columns). Therefore, we will talk about 2D convolution.\n",
    "\n",
    "If we have our input image $f_{in}$ and a kernel K, the convolution is defined by:\n",
    "\n",
    "$$f_{out}(x,y)=K*f_{in}(x,y)= \\sum_{s}\\sum_{t}K(s,t)f_{in}(x-s,y-t)$$\n",
    "\n",
    "where $f_{out}(x,y)$ is the value of the pixel $(x,y)$ of the output image $f_{out}$.\n",
    "In this exercise we are going to consider **cross correlation** as a simplified technique of the convolution.\n",
    "\n",
    "Note: Cross correlation is implemented in a lot of machine learning libraries (as Pytorch and Tensorflow) and many times they called it **convolution**. DON'T GET CONFUSED!!! In that case you need to flip the kernel :)\n",
    "\n",
    "Cross correlation only considers the sum of the elementwise product between the kernel and the sub-image region considered. Formally, this is defined as:\n",
    "\n",
    "$$f_{out}(x,y)=K\\star f_{in}(x,y)= \\sum_{s}\\sum_{t}K(s,t)f_{in}(x+s,y+t)$$\n",
    "\n",
    "The following GIF shows how to perform the cross-correlation between an image and a kernel:\n",
    "\n",
    "![alt text](3D_Convolution_Animation.gif \"Cross correlation\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Understanding convolution\n",
    "In general for the exercises:\n",
    "\n",
    "- *Italics indicate text to explain the motivation or process behind a task*\n",
    "\n",
    "- **Bold text indicates a task**\n",
    "\n",
    "- Finally, \\* (one star) and ** (two stars) indicates a difficult or a particuarly difficult task, respectively. These are especially optional!\n",
    "\n",
    "Firstly we will run some code to load an image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from ctypes import c_char\n",
    "\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d as scipy_conv2d\n",
    "from os.path import join\n",
    "from time import time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "image_gray = np.array(Image.open(join('images', 'kb_grayscale.jpg')))\n",
    "print(image_gray.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define a function to show images "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def show_image(image, name='', cmap='gray', show=True, vmin=0, vmax=255):\n",
    "    plt.imshow(image, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    plt.title(name)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**1. Inspect the following code where np.pad is used to pad the image. Change the values of the padding_size variable to get an understanding of which value relates to which dimension.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "padding_size = [[100, 10], [30, 50]] # ((top, bottom), (left, right))\n",
    "# Sadly the variable arguments for np.pad make a loop possible but ugly\n",
    "image_padded_constant = np.pad(image_gray, padding_size, mode='constant', constant_values=0)\n",
    "image_padded_reflect = np.pad(image_gray, padding_size, mode='reflect', )\n",
    "image_padded_wrap = np.pad(image_gray, padding_size, mode='wrap')\n",
    "image_padded_edge = np.pad(image_gray, padding_size, mode='edge')\n",
    "\n",
    "show_image(image_gray, name=f'Image of shape {image_gray.shape} original image')\n",
    "show_image(image_padded_constant, name=f'Image of shape {image_padded_constant.shape} padded using constant')\n",
    "show_image(image_padded_reflect, name=f'Image of shape {image_padded_reflect.shape} padded using reflect')\n",
    "show_image(image_padded_wrap, name=f'Image of shape {image_padded_wrap.shape} padded using wrap')\n",
    "show_image(image_padded_edge, name=f'Image of shape {image_padded_edge.shape} padded using edge')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**2. Time to implement your own convolution function, it should do a valid convolution. Remember to flip the kernel!! (\\*Optional)**\n",
    "*A valid convolution does not apply any padding to the input image*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# If you at any point get stuck or just want to continue with the other exercises, just copy the solution:)\n",
    "def convolution2d(image, kernel):\n",
    "    assert kernel.shape[0] % 2 == 1 and kernel.shape[1] % 2 == 1, 'kernel must be an odd number for this convolution function'\n",
    "    # Flip the kernel\n",
    "    kernel = np.flipud(np.fliplr(?))\n",
    "    \n",
    "    # Get the dimensions of the image and the kernel\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    \n",
    "    # Compute the output dimensions\n",
    "    output_height = ?\n",
    "    output_width = ?\n",
    "    \n",
    "    # Initialize the output matrix\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # Perform 2D convolution\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            output[i,j] = np.sum(?)\n",
    "    \n",
    "    return output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*Use the cell below to test your implementation and the next cell to compare your implementation to scipy's*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# First example from group discussion:\n",
    "print(\"w (kernel):\")\n",
    "w       = np.array([[1,2,1]])\n",
    "print(w)\n",
    "print(\"input array:\")\n",
    "f_in    = np.array([[0,1,0],[0,2,0],[0,3,0]])\n",
    "print(f_in)\n",
    "f_out   = convolution2d(f_in,w)\n",
    "print(\"valid output:\")\n",
    "print(f_out)\n",
    "print(\"f_in zero padded:\")\n",
    "f_padded = np.pad(f_in, [(0, 0), (1,1)], constant_values=0)\n",
    "print(f_padded)\n",
    "f_out_padded   = convolution2d(f_padded, w) # note here that we use scipy's implementation since our's do zero padding.\n",
    "print(\"zero padded after convolution:\")\n",
    "print(f_out_padded)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Validate that our implementation matches scipy's\n",
    "f_out_scipy = scipy_conv2d(f_in,w,mode=\"valid\")\n",
    "f_out_scipy_padded = scipy_conv2d(f_in,w,mode=\"same\")\n",
    "\n",
    "print(f'Difference between own convolution and scipy:\\n'\n",
    "      f'\\t\\t\\t\\tScipy\\tOwn\\n'\n",
    "      f'Shape valid:\\t{f_out.shape}, {f_out_scipy.shape}\\n'\n",
    "      f'Diff valid: {np.sum(f_out - f_out_scipy)}\\n'\n",
    "      f'Shape same:\\t\\t{f_out_padded.shape}, {f_out_scipy_padded.shape}\\n'\n",
    "      f'Diff same: {np.sum(f_out_padded - f_out_scipy_padded)}\\n'\n",
    "      )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Kernel design\n",
    "\n",
    "\n",
    "You should use the 2D convolution function from the previous exercise to compute the convolution between the image you loaded before and some simple kernels/filters that can make the image blurry or sharp and can be used to highlight the edges.  \n",
    "\n",
    "- The first filter is blurry filter, in its 3x3 shape, this is given by the following matrix:\n",
    "\n",
    "  $$ F_{blurry} = \\frac{1}{9} \\left[ {\\begin{array}{ccc} 1&1&1\\\\1&1&1\\\\1&1&1 \\end{array}} \\right] $$\n",
    "                                   \n",
    "    where the normalization factor is computed by $\\frac{1}{\\sum_{i,j}F_{i,j}}$.\n",
    "\n",
    "    - In case the image is a high-definition image, we suggest you to create a larger filter to actually see the blurrying effect (try 7x7 or 11x11)!\n",
    " **1. Why does this kernel blur the image?**\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We need a function to translate the image to floats in the range (0, 1):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def img_as_float(image):\n",
    "    return image / 255.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_float = img_as_float(image_gray)\n",
    "# Implement the kernel for F_blurry\n",
    "F_blurry =?"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**2. Apply your convolution function to the image using the blurry kernel **"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_float_padded = np.pad(img_float, ((1,1), (1,1)), constant_values=0)\n",
    "t = time()\n",
    "img_blur = convolution2d(img_float_padded, F_blurry)\n",
    "time_own = time() - t\n",
    "show_image(img_blur, name='blurry', vmin=0, vmax=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*It is all well and good to write nice functions that do the job, but if a third party library for python can do the same thing, chances are they do it significantly faster than your own.\n",
    "As an illustration for why you should use libraries and not your own implementations in most cases notice the difference in run time between the two (and we will use scipy's from now on):* "
   ]
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "t = time()\n",
    "img_blur = scipy_conv2d(img_float, F_blurry, mode='same')\n",
    "time_scipy = time() - t\n",
    "show_image(img_blur, name='Blurry', vmin=0, vmax=1)\n",
    "print(f'Own took {time_own:.4f}, Scipy took {time_scipy:.4f}, so {time_scipy/time_own * 100: .2f} % of your implementation')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**3. \\*See if you can improve and optimise your own implementation to reduce the gap between the two.**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4. Implement the following two filters:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The second filter you are going to apply is used to sharpen the image, this is given by:\n",
    "\n",
    "  $$ F_{sharp} = \\left[ {\\begin{array}{ccc}0&-1&0\\\\-1&7&-1\\\\0&-1&0\\end{array}} \\right] $$ "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Implement the kernel for F_sharp\n",
    "F_sharp = ?\n",
    "img_sharp =scipy_conv2d(img_float,F_sharp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The last filter is used to highlight the edges of the objects in the image. This filter is an approximation of a Laplacian filter. The Laplacian is the measure of the 2nd derivative of an image. Therefore if we have an image with pixel intensity values $f_{in}(x,y)$, the Laplacian is given by $\\frac{\\partial^2 I}{\\partial i^2} + \\frac{\\partial^2 I}{\\partial j^2}$.\n",
    "\n",
    "$$ F_{edge} = \\left[ {\\begin{array}{ccc}0&1&0\\\\1&-4&1\\\\0&1&0\\end{array}} \\right] $$ \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Implement the kernel for F_edge\n",
    "F_edge  = ?\n",
    "\n",
    "img_edge = scipy_conv2d(img_float,F_edge)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Here are some suggestions for things you could test:*\n",
    "- What happens if you run the sharpen filter on blurry image? Try it.\n",
    "- Try to filter an image multiple time. What happens to the intensity lines?\n",
    "\n",
    "**4. Look at the output of the image filtered with the sharpening kernel in the following cell and explain what you see.**\n",
    " \n",
    "*Hint: Inspect the maximum value* "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize = (20,15))\n",
    "plt.subplot(2,2, 1)\n",
    "show_image(img_float, name='Original image', show=False, vmin=0, vmax=1)\n",
    "\n",
    "plt.subplot(2,2, 2)\n",
    "show_image(img_blur, name='Blurry', show=False, vmin=0, vmax=1)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "# Notice that since the values of the sharpening filter have a sum greater than 1 and thus may result in pixel values greater than 1.\n",
    "show_image(img_sharp, name='Sharp', show=False, vmin=0, vmax=1)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "show_image(img_edge, name='Edge', show=False, vmin=0, vmax=1)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**5. Try increasing the kernel size for the blurring filter and compare the effects.**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "size = (?, ?)\n",
    "F_blurry = ? / ?\n",
    "\n",
    "img_blur =scipy_conv2d(img_float,F_blurry)\n",
    "\n",
    "show_image(img_blur, name='Blurry', show=True, vmin=0, vmax=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**6. What happens to the image if we do not change the range to (0, 1) and use a kernel with values that do not sum to 1?**\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "size = (?, ?)\n",
    "F_blurry_large = ?\n",
    "\n",
    "img_blur =scipy_conv2d(image_gray, F_blurry_large)\n",
    "\n",
    "show_image(img_blur, name='Blurry with unnormalised kernel values', show=True, vmin=0, vmax=255)\n",
    "print(img_blur.min(), img_blur.max())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Sobel filter\n",
    "\n",
    "In this exercise you are going to apply a more sophisticated edge detection filter than the one you used in the previous exercise. We will apply a Sobel filter to the original image. The Sobel filter (also known as Sobel operator https://en.wikipedia.org/wiki/Sobel_operator) is composed by these two different filters:\n",
    "\n",
    "$$ F_{v} = \\left[ {\\begin{array}{ccc}-1&0&1\\\\-2&0&2\\\\-1&0&1\\end{array}} \\right] $$ \n",
    "                                   \n",
    "$$ F_{h} = \\left[ {\\begin{array}{ccc}-1&-2&-1\\\\0&0&0\\\\1&2&1\\end{array}} \\right] $$ \n",
    "                                  \n",
    "These two filter, when convoluted with an image, are approximating the derivatives for the vertical and horizontal changes. Indeed, we have that we have that the value of the derivative is high when there is an high difference between neighbours pixels. And that is exactly where an edge is. \n",
    "\n",
    "If we denoted with $G_{v}$ and $G_{h}$ the resulting filtered images obtained by the convolution between $F_{v}$ and $F_{h}$ with the original image, we can use them to compute the approximation of the gradient for each point in the image by computing:\n",
    "\n",
    "$$ G = \\sqrt{ G_{v}^2 + G_{h}^2} $$\n",
    "\n",
    "\n",
    "The code below does the following:\n",
    "- Computes the two $G_{v}$ and $G_{h}$ filtered image and plot them. Comment on the resulting plots.\n",
    "- Computes G and plot it. Compare the plot obtained by using this approach and the one using the single filter in previous the exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sobel_kernel_v = ?\n",
    "sobel_kernel_h = ?\n",
    "\n",
    "G_v = scipy_conv2d(img_float,sobel_kernel_v)\n",
    "G_h = scipy_conv2d(img_float,sobel_kernel_h)\n",
    "G   = ?\n",
    "\n",
    "show_image(G_v, name='Sobel vertical convolution' , vmin=0, vmax=1)\n",
    "show_image(G_h, name='Sobel horizontal convolution', vmin=0, vmax=1)\n",
    "show_image(G, name='Edge enhancement combining the two sobel', vmin=0, vmax=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 RGB images\n",
    "Now we shall see, that the techniques you just used for grayscale images are also applicable to color images, but instead the convolution is done for each color dimension (One could also imagine applications where we apply a 3D filter to the image, treating the channels as a 3rd dimension).\n",
    "\n",
    "**1. Apply the filters from exercise 3 to the different channels of the following RGB image:**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "img_rgb = np.array(Image.open((join('images', 'field.png')))) # load image\n",
    "print(np.shape(img_rgb))\n",
    "show_image(img_rgb, ('Original RGB image'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "#filter the image, up to you which filters to use where\n",
    "r_filter = ?\n",
    "g_filter = ?\n",
    "b_filter = ?\n",
    "\n",
    "# extract the three channels\n",
    "r_channel = img_as_float(img_rgb[:, :, 0])\n",
    "g_channel = img_as_float(img_rgb[:, :, 1])\n",
    "b_channel = img_as_float(img_rgb[:, :, 2])\n",
    "\n",
    "r_fil = scipy_conv2d(r_channel,r_filter)\n",
    "g_fil = scipy_conv2d(r_channel,g_filter)\n",
    "b_fil = scipy_conv2d(r_channel,b_filter)\n",
    "\n",
    "fig = plt.figure(figsize = (20, 30))\n",
    "\n",
    "plt.subplot(4, 2, 1)\n",
    "show_image(r_channel, cmap='Reds', vmin=0, vmax=1, name='Red channel', show=False)\n",
    "plt.subplot(4, 2, 2)\n",
    "show_image(r_fil, cmap='Reds', vmin=0, vmax=1, name='Red channel after convolution', show=False)\n",
    "\n",
    "plt.subplot(4, 2, 3)\n",
    "show_image(r_channel, cmap='Greens', vmin=0, vmax=1, name='Green channel', show=False)\n",
    "plt.subplot(4, 2, 4)\n",
    "show_image(r_fil, cmap='Greens', vmin=0, vmax=1, name='Green channel after convolution', show=False)\n",
    "\n",
    "plt.subplot(4, 2, 5)\n",
    "show_image(r_channel, cmap='Blues', vmin=0, vmax=1, name='Blue channel', show=False)\n",
    "plt.subplot(4, 2, 6)\n",
    "show_image(r_fil, cmap='Blues', vmin=0, vmax=1, name='Blue channel after convolution', show=False)\n",
    "\n",
    "plt.subplot(4, 2, 7)\n",
    "channels = np.stack((r_channel, g_channel,b_channel,), axis=-1)\n",
    "show_image(channels, name='Original image', cmap='viridis', show=False, vmin=0, vmax=1)\n",
    "\n",
    "# adding the results of the convolutions\n",
    "final = np.stack((r_fil, g_fil, b_fil), axis=-1)\n",
    "plt.subplot(4, 2, 8)\n",
    "show_image(final, cmap='viridis', vmin=0, vmax=1, name='All channels after convolution')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**2. What happens when you combine different filters on different channels?**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (Cross)-Entropy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "**1. Discuss (and write down) what cross-entropy measures in your own words**\n",
    "\n",
    "$\\dots$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 2.2:\n",
    "\n",
    "*Assume you have a prediction from a neural network, with 3 probabilities denoting the\n",
    "certainty. You also have a one-hot encoded vector which is 0 everywhere but in the place\n",
    "which corresponds to the correct class.*\n",
    "\n",
    "**1. How should the prediction probabilities look if you wanted to maximize cross-entropy?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. How about if you wanted to minimize it?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. Do you see any potential issues with a neural network using this loss?** (*Hint: Check out [On Calibration of Modern Neural Networks](https://arxiv.org/abs/1706.04599) p. 4: NLL*)\n",
    "\n",
    "$\\dots$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
